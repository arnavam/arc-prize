{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZpbuuB4vy8h","executionInfo":{"status":"ok","timestamp":1753846137989,"user_tz":-330,"elapsed":21764,"user":{"displayName":"arnav jagadeesh","userId":"07454715082396678244"}},"outputId":"0a91e74c-4b84-430f-f3d7-03039aba5cbf"},"id":"UZpbuuB4vy8h","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","execution_count":5,"id":"546a49ab","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"546a49ab","executionInfo":{"status":"ok","timestamp":1753846161860,"user_tz":-330,"elapsed":6326,"user":{"displayName":"arnav jagadeesh","userId":"07454715082396678244"}},"outputId":"e152d750-87b8-428e-f256-b3ae631fd3b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 1.3795\n","Epoch 2/5\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.4348e-04\n","Epoch 3/5\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0000e+00\n","Epoch 4/5\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0000e+00\n","Epoch 5/5\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0000e+00\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n","Solution: None\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import json\n","from sklearn.cluster import KMeans\n","from itertools import product\n","import os\n","\n","# --- Neural Feature Extractor ---\n","def create_feature_extractor(input_shape=(30, 30, 1)):\n","    \"\"\"Creates a CNN model for feature extraction from grids\"\"\"\n","    model = models.Sequential([\n","        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(64, (3, 3), activation='relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(128, (3, 3), activation='relu'),\n","        layers.Flatten(),\n","        layers.Dense(256, activation='relu'),\n","        layers.Dropout(0.3),\n","        layers.Dense(128, name='feature_vector')\n","    ])\n","    return model\n","\n","# --- Symbolic Program Generator ---\n","PRIMITIVES = [\n","    'rotate', 'mirrorlr', 'mirrorud', 'lcrop', 'rcrop', 'ucrop', 'dcrop',\n","    'recolor', 'select', 'fill', 'overlay', 'resize'\n","]\n","\n","def generate_programs(max_length=3):\n","    \"\"\"Generates symbolic programs of primitive operations\"\"\"\n","    programs = []\n","    for length in range(1, max_length + 1):\n","        for combo in product(PRIMITIVES, repeat=length):\n","            programs.append(list(combo))\n","    return programs\n","\n","# --- Differentiable Program Executor ---\n","class ProgramExecutor(tf.keras.Model):\n","    \"\"\"Differentiable executor for symbolic programs\"\"\"\n","    def __init__(self, feature_extractor, num_primitives):\n","        super().__init__()\n","        self.feature_extractor = feature_extractor\n","        self.primitive_weights = layers.Dense(num_primitives, activation='softmax')\n","\n","    def call(self, inputs):\n","        # Extract features from input/output pairs\n","        input_grid, output_grid = inputs\n","        input_feat = self.feature_extractor(input_grid)\n","        output_feat = self.feature_extractor(output_grid)\n","\n","        # Compute primitive probabilities\n","        combined = tf.concat([input_feat, output_feat], axis=-1)\n","        return self.primitive_weights(combined)\n","\n","# --- Neural-Symbolic Solver ---\n","class NeuralSymbolicSolver:\n","    def __init__(self):\n","        self.feature_extractor = create_feature_extractor()\n","        self.executor = ProgramExecutor(self.feature_extractor, len(PRIMITIVES))\n","        self.executor.compile(\n","            optimizer='adam',\n","            loss='categorical_crossentropy'\n","        )\n","        self.programs = generate_programs(max_length=3)\n","\n","    def train(self, train_data, epochs=10, batch_size=32):\n","        \"\"\"Train on demonstration pairs\"\"\"\n","        # Prepare training data\n","        X_in, X_out, y_primitive = [], [], []\n","\n","        for example in train_data:\n","            input_grid = self.preprocess(example['input'])\n","            output_grid = self.preprocess(example['output'])\n","\n","            # Find best primitive (simplified for example)\n","            best_primitive = self.find_best_primitive(input_grid, output_grid)\n","\n","            X_in.append(input_grid)\n","            X_out.append(output_grid)\n","            y_primitive.append(PRIMITIVES.index(best_primitive))\n","\n","        # Train the model\n","        X_in = np.array(X_in)\n","        X_out = np.array(X_out)\n","        y_primitive = tf.keras.utils.to_categorical(y_primitive, len(PRIMITIVES))\n","\n","        self.executor.fit(\n","            [X_in, X_out], y_primitive,\n","            epochs=epochs,\n","            batch_size=batch_size\n","        )\n","\n","    def solve(self, input_grid, output_grid):\n","        \"\"\"Solve a new problem using neural-guided program synthesis\"\"\"\n","        # Predict primitive probabilities\n","        input_pp = self.preprocess(input_grid)\n","        output_pp = self.preprocess(output_grid)\n","        primitive_probs = self.executor.predict(\n","            [np.array([input_pp]), np.array([output_pp])]\n","        )[0]\n","\n","        # Rank programs by primitive probabilities\n","        program_scores = []\n","        for program in self.programs:\n","            score = np.prod([primitive_probs[PRIMITIVES.index(p)] for p in program])\n","            program_scores.append((program, score))\n","\n","        # Try top programs\n","        program_scores.sort(key=lambda x: x[1], reverse=True)\n","\n","        for program, _ in program_scores[:10]:  # Try top 10\n","            result = self.execute_program(input_grid, program)\n","            if np.array_equal(result, output_grid):\n","                return program\n","\n","        return None  # No solution found\n","\n","    def execute_program(self, grid, program):\n","        \"\"\"Execute a symbolic program on a grid\"\"\"\n","        current = np.array(grid)\n","        for op in program:\n","            if op == 'rotate':\n","                current = np.rot90(current, k=-1)\n","            elif op == 'mirrorlr':\n","                current = np.fliplr(current)\n","            elif op == 'mirrorud':\n","                current = np.flipud(current)\n","            elif op == 'lcrop':\n","                current = current[:, 1:] if current.shape[1] > 1 else current\n","            elif op == 'rcrop':\n","                current = current[:, :-1] if current.shape[1] > 1 else current\n","            elif op == 'ucrop':\n","                current = current[1:, :] if current.shape[0] > 1 else current\n","            elif op == 'dcrop':\n","                current = current[:-1, :] if current.shape[0] > 1 else current\n","            elif op == 'recolor':\n","                current = self.learn_recoloring(current)\n","            # Additional operations would be implemented here\n","        return current\n","\n","    def learn_recoloring(self, grid):\n","        \"\"\"Learn color mapping using clustering (simplified)\"\"\"\n","        # In practice, this would compare input/output colors\n","        return grid  # Placeholder\n","\n","    def find_best_primitive(self, input_grid, output_grid):\n","        \"\"\"Find best matching primitive (simplified heuristic)\"\"\"\n","        # In practice, use neural features for this\n","        for primitive in ['rotate', 'mirrorlr', 'mirrorud']:\n","            transformed = self.execute_program(input_grid, [primitive])\n","            if np.array_equal(transformed, output_grid):\n","                return primitive\n","        return 'recolor'  # Default\n","\n","    def preprocess(self, grid, size=30):\n","        \"\"\"Preprocess grid to fixed size with padding\"\"\"\n","        h, w = len(grid), len(grid[0])\n","        padded = np.zeros((size, size), dtype=int)\n","        padded[:h, :w] = grid\n","        return np.expand_dims(padded, axis=-1)\n","\n","# --- Main Execution ---\n","if __name__ == \"__main__\":\n","    # Load training data\n","    file_path = 'drive/MyDrive/Colab Notebooks/arc-prize-2025/arc-prize-2025/arc-agi_training_challenges.json'\n","    if not os.path.exists(file_path):\n","        print(f\"Error: File not found at {file_path}\")\n","        print(\"Please ensure your Google Drive is mounted correctly and the file path is correct.\")\n","        print(\"To mount your Drive, you can use the following code in a new cell:\")\n","        print(\"from google.colab import drive\\ndrive.mount('/content/drive')\")\n","    else:\n","        with open(file_path, 'r') as f:\n","            train_data = json.load(f)\n","\n","        # Prepare training examples\n","        training_examples = []\n","        for case_id, case_data in train_data.items():\n","            for example in case_data['train']:\n","                training_examples.append({\n","                    'input': example['input'],\n","                    'output': example['output']\n","                })\n","\n","        # Initialize and train solver\n","        solver = NeuralSymbolicSolver()\n","        solver.train(training_examples[:100], epochs=5, batch_size=16)\n","\n","        # Test on a sample case\n","        sample_case = list(train_data.values())[0]\n","        input_grid = sample_case['train'][0]['input']\n","        output_grid = sample_case['train'][0]['output']\n","\n","        solution = solver.solve(input_grid, output_grid)\n","        print(f\"Solution: {solution}\")\n","\n","        # Visualize results\n","        if solution:\n","            result = solver.execute_program(input_grid, solution)\n","            print(\"Original Input:\")\n","            print(np.array(input_grid))\n","            print(\"\\nSolved Output:\")\n","            print(result)\n","            print(\"\\nTarget Output:\")\n","            print(np.array(output_grid))"]},{"cell_type":"code","source":[],"metadata":{"id":"S6-41qc0vtoR"},"id":"S6-41qc0vtoR","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"14db4a26"},"source":["# Task\n","Fix the provided code so that it can find a solution to the ARC task."],"id":"14db4a26"},{"cell_type":"markdown","metadata":{"id":"3bfcf1e6"},"source":["## Enhance `find best primitive`\n","\n","### Subtask:\n","Enhance the `find_best_primitive` function to be more robust by considering all primitives and using a similarity metric to find the best one.\n"],"id":"3bfcf1e6"},{"cell_type":"markdown","metadata":{"id":"c1edad94"},"source":["**Reasoning**:\n","I will now modify the `find_best_primitive` function to iterate through all primitives, apply them, and calculate the negative mean squared error to find the best-matching primitive, as outlined in the instructions. This will make the primitive selection process more robust and less reliant on a fixed, hardcoded order. I will also need to modify the `execute_program` function to handle single primitive operations correctly.\n","\n"],"id":"c1edad94"},{"cell_type":"code","metadata":{"id":"6591f295","executionInfo":{"status":"ok","timestamp":1753846497709,"user_tz":-330,"elapsed":32,"user":{"displayName":"arnav jagadeesh","userId":"07454715082396678244"}}},"source":["def find_best_primitive(self, input_grid, output_grid):\n","    \"\"\"Find best matching primitive using a similarity metric.\"\"\"\n","    best_primitive = None\n","    max_similarity = -np.inf\n","\n","    for primitive in PRIMITIVES:\n","        transformed_grid = self.execute_program(np.array(input_grid), [primitive])\n","\n","        # Ensure transformed_grid and output_grid have the same shape for comparison\n","        h_out, w_out = output_grid.shape\n","        h_trans, w_trans = transformed_grid.shape\n","\n","        padded_transformed = np.zeros_like(output_grid)\n","\n","        min_h = min(h_out, h_trans)\n","        min_w = min(w_out, w_trans)\n","\n","        padded_transformed[:min_h, :min_w] = transformed_grid[:min_h, :min_w]\n","\n","        # Using negative mean squared error as similarity\n","        similarity = -np.mean((padded_transformed - output_grid) ** 2)\n","\n","        if similarity > max_similarity:\n","            max_similarity = similarity\n","            best_primitive = primitive\n","\n","    return best_primitive\n","\n","NeuralSymbolicSolver.find_best_primitive = find_best_primitive\n","\n","# We need to ensure the `execute_program` function can handle the numpy array format\n","def execute_program(self, grid, program):\n","    \"\"\"Execute a symbolic program on a grid\"\"\"\n","    current = np.array(grid)\n","    for op in program:\n","        if op == 'rotate':\n","            current = np.rot90(current, k=-1)\n","        elif op == 'mirrorlr':\n","            current = np.fliplr(current)\n","        elif op == 'mirrorud':\n","            current = np.flipud(current)\n","        elif op == 'lcrop':\n","            current = current[:, 1:] if current.shape[1] > 1 else current\n","        elif op == 'rcrop':\n","            current = current[:, :-1] if current.shape[1] > 1 else current\n","        elif op == 'ucrop':\n","            current = current[1:, :] if current.shape[0] > 1 else current\n","        elif op == 'dcrop':\n","            current = current[:-1, :] if current.shape[0] > 1 else current\n","        elif op == 'recolor':\n","            current = self.learn_recoloring(current)\n","        # Additional operations would be implemented here\n","    return current\n","\n","NeuralSymbolicSolver.execute_program = execute_program"],"id":"6591f295","execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"afe7545d"},"source":["## Expand program search\n","\n","### Subtask:\n","Increase the number of programs the solver attempts from the top 10 to a larger number (e.g., top 50 or 100).\n"],"id":"afe7545d"},{"cell_type":"markdown","metadata":{"id":"53d5aabf"},"source":["**Reasoning**:\n","I need to modify the `solve` method in the `NeuralSymbolicSolver` class to change the number of programs attempted from the top 10 to the top 50.\n","\n"],"id":"53d5aabf"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29ce2308","executionInfo":{"status":"ok","timestamp":1753846525264,"user_tz":-330,"elapsed":6567,"user":{"displayName":"arnav jagadeesh","userId":"07454715082396678244"}},"outputId":"ea28b353-4ef2-4fb7-c351-c41af2fc5a62"},"source":["class NeuralSymbolicSolver:\n","    def __init__(self):\n","        self.feature_extractor = create_feature_extractor()\n","        self.executor = ProgramExecutor(self.feature_extractor, len(PRIMITIVES))\n","        self.executor.compile(\n","            optimizer='adam',\n","            loss='categorical_crossentropy'\n","        )\n","        self.programs = generate_programs(max_length=3)\n","\n","    def train(self, train_data, epochs=10, batch_size=32):\n","        \"\"\"Train on demonstration pairs\"\"\"\n","        # Prepare training data\n","        X_in, X_out, y_primitive = [], [], []\n","\n","        for example in train_data:\n","            input_grid = self.preprocess(example['input'])\n","            output_grid = self.preprocess(example['output'])\n","\n","            # Find best primitive (simplified for example)\n","            best_primitive = self.find_best_primitive(np.array(example['input']), np.array(example['output'])) # Ensure numpy arrays are passed\n","\n","            X_in.append(input_grid)\n","            X_out.append(output_grid)\n","            y_primitive.append(PRIMITIVES.index(best_primitive))\n","\n","        # Train the model\n","        X_in = np.array(X_in)\n","        X_out = np.array(X_out)\n","        y_primitive = tf.keras.utils.to_categorical(y_primitive, len(PRIMITIVES))\n","\n","        self.executor.fit(\n","            [X_in, X_out], y_primitive,\n","            epochs=epochs,\n","            batch_size=batch_size\n","        )\n","\n","    def solve(self, input_grid, output_grid):\n","        \"\"\"Solve a new problem using neural-guided program synthesis\"\"\"\n","        # Predict primitive probabilities\n","        input_pp = self.preprocess(input_grid)\n","        output_pp = self.preprocess(output_grid)\n","        primitive_probs = self.executor.predict(\n","            [np.array([input_pp]), np.array([output_pp])]\n","        )[0]\n","\n","        # Rank programs by primitive probabilities\n","        program_scores = []\n","        for program in self.programs:\n","            score = np.prod([primitive_probs[PRIMITIVES.index(p)] for p in program])\n","            program_scores.append((program, score))\n","\n","        # Try top programs\n","        program_scores.sort(key=lambda x: x[1], reverse=True)\n","\n","        for program, _ in program_scores[:50]:  # Try top 50 instead of 10\n","            result = self.execute_program(input_grid, program)\n","            if np.array_equal(result, output_grid):\n","                return program\n","\n","        return None  # No solution found\n","\n","    def execute_program(self, grid, program):\n","        \"\"\"Execute a symbolic program on a grid\"\"\"\n","        current = np.array(grid)\n","        for op in program:\n","            if op == 'rotate':\n","                current = np.rot90(current, k=-1)\n","            elif op == 'mirrorlr':\n","                current = np.fliplr(current)\n","            elif op == 'mirrorud':\n","                current = np.flipud(current)\n","            elif op == 'lcrop':\n","                current = current[:, 1:] if current.shape[1] > 1 else current\n","            elif op == 'rcrop':\n","                current = current[:, :-1] if current.shape[1] > 1 else current\n","            elif op == 'ucrop':\n","                current = current[1:, :] if current.shape[0] > 1 else current\n","            elif op == 'dcrop':\n","                current = current[:-1:, :] if current.shape[0] > 1 else current # Fixed typo here\n","            elif op == 'recolor':\n","                current = self.learn_recoloring(current)\n","            # Additional operations would be implemented here\n","        return current\n","\n","    def learn_recoloring(self, grid):\n","        \"\"\"Learn color mapping using clustering (simplified)\"\"\"\n","        # In practice, this would compare input/output colors\n","        return grid  # Placeholder\n","\n","    def find_best_primitive(self, input_grid, output_grid):\n","        \"\"\"Find best matching primitive using a similarity metric.\"\"\"\n","        best_primitive = None\n","        max_similarity = -np.inf\n","\n","        for primitive in PRIMITIVES:\n","            transformed_grid = self.execute_program(np.array(input_grid), [primitive])\n","\n","            # Ensure transformed_grid and output_grid have the same shape for comparison\n","            h_out, w_out = output_grid.shape\n","            h_trans, w_trans = transformed_grid.shape\n","\n","            # Calculate padding needed\n","            pad_h = max(0, h_out - h_trans)\n","            pad_w = max(0, w_out - w_trans)\n","\n","            # Pad the transformed grid\n","            padded_transformed = np.pad(transformed_grid, ((0, pad_h), (0, pad_w)), mode='constant', constant_values=0)\n","\n","            # Trim padded_transformed if it's larger than output_grid (shouldn't happen with padding logic, but as a safeguard)\n","            padded_transformed = padded_transformed[:h_out, :w_out]\n","\n","\n","            # Using negative mean squared error as similarity\n","            similarity = -np.mean((padded_transformed - output_grid) ** 2)\n","\n","            if similarity > max_similarity:\n","                max_similarity = similarity\n","                best_primitive = primitive\n","\n","        return best_primitive\n","\n","\n","    def preprocess(self, grid, size=30):\n","        \"\"\"Preprocess grid to fixed size with padding\"\"\"\n","        h, w = len(grid), len(grid[0])\n","        padded = np.zeros((size, size), dtype=int)\n","        padded[:h, :w] = grid\n","        return np.expand_dims(padded, axis=-1)\n","\n","# Re-instantiate the solver with the modified class definition\n","solver = NeuralSymbolicSolver()\n","\n","# Train the solver again with the updated class\n","# Prepare training examples\n","training_examples = []\n","for case_id, case_data in train_data.items():\n","    for example in case_data['train']:\n","        training_examples.append({\n","            'input': example['input'],\n","            'output': example['output']\n","        })\n","\n","solver.train(training_examples[:100], epochs=5, batch_size=16)\n","\n","# Test on a sample case\n","sample_case = list(train_data.values())[0]\n","input_grid = sample_case['train'][0]['input']\n","output_grid = sample_case['train'][0]['output']\n","\n","solution = solver.solve(input_grid, output_grid)\n","print(f\"Solution: {solution}\")\n","\n","# Visualize results\n","if solution:\n","    result = solver.execute_program(input_grid, solution)\n","    print(\"Original Input:\")\n","    print(np.array(input_grid))\n","    print(\"\\nSolved Output:\")\n","    print(result)\n","    print(\"\\nTarget Output:\")\n","    print(np.array(output_grid))\n"],"id":"29ce2308","execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 2.3115\n","Epoch 2/5\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.7963\n","Epoch 3/5\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.6187\n","Epoch 4/5\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.5310\n","Epoch 5/5\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.1784\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n","Solution: None\n"]}]},{"cell_type":"markdown","metadata":{"id":"0a990588"},"source":["## Improve training\n","\n","### Subtask:\n","Modify the training process to use a larger portion of the training data and train for more epochs to allow the model to learn more effectively.\n"],"id":"0a990588"},{"cell_type":"markdown","metadata":{"id":"2b004bd9"},"source":["**Reasoning**:\n","Modify the main execution block to use a larger portion of the training data and increase the number of epochs for training.\n","\n"],"id":"2b004bd9"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5f7261f","executionInfo":{"status":"ok","timestamp":1753846566880,"user_tz":-330,"elapsed":25204,"user":{"displayName":"arnav jagadeesh","userId":"07454715082396678244"}},"outputId":"5f3252ec-e3b7-4232-ed39-8e37374d5943"},"source":["# Re-instantiate the solver with the current class definition\n","solver = NeuralSymbolicSolver()\n","\n","# Prepare training examples\n","training_examples = []\n","for case_id, case_data in train_data.items():\n","    for example in case_data['train']:\n","        training_examples.append({\n","            'input': example['input'],\n","            'output': example['output']\n","        })\n","\n","# Train the solver again with increased data and epochs\n","solver.train(training_examples[:500], epochs=15, batch_size=16) # Increased data to 500 and epochs to 15\n","\n","# Test on a sample case\n","sample_case = list(train_data.values())[0]\n","input_grid = sample_case['train'][0]['input']\n","output_grid = sample_case['train'][0]['output']\n","\n","solution = solver.solve(input_grid, output_grid)\n","print(f\"Solution: {solution}\")\n","\n","# Visualize results\n","if solution:\n","    result = solver.execute_program(input_grid, solution)\n","    print(\"Original Input:\")\n","    print(np.array(input_grid))\n","    print(\"\\nSolved Output:\")\n","    print(result)\n","    print(\"\\nTarget Output:\")\n","    print(np.array(output_grid))"],"id":"c5f7261f","execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 2.2227\n","Epoch 2/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 1.8473\n","Epoch 3/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.5790\n","Epoch 4/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.4356\n","Epoch 5/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.3597\n","Epoch 6/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.1557\n","Epoch 7/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.9853\n","Epoch 8/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.9432\n","Epoch 9/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.7012\n","Epoch 10/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.6926\n","Epoch 11/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.7189\n","Epoch 12/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.5866\n","Epoch 13/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.3938\n","Epoch 14/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4311\n","Epoch 15/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.2720\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n","Solution: None\n"]}]},{"cell_type":"markdown","metadata":{"id":"ac80b77c"},"source":["## Refine feature extractor\n","\n","### Subtask:\n","Refine the feature extractor architecture to better capture the salient features of the input grids.\n"],"id":"ac80b77c"},{"cell_type":"markdown","metadata":{"id":"84102536"},"source":["**Reasoning**:\n","I will redefine the `create_feature_extractor` function to include `BatchNormalization` layers after each `Conv2D` and `Dense` layer, increase the number of filters in the `Conv2D` layers to 64, 128, and 256, and increase the number of units in the final `Dense` layer to 256, as per the instructions. Then, I will re-run the training and solving pipeline to evaluate the impact of these changes.\n","\n"],"id":"84102536"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"037deb62","executionInfo":{"status":"ok","timestamp":1753846658898,"user_tz":-330,"elapsed":69223,"user":{"displayName":"arnav jagadeesh","userId":"07454715082396678244"}},"outputId":"3022f227-dbfa-4457-c6a2-acff4161bf1e"},"source":["def create_feature_extractor(input_shape=(30, 30, 1)):\n","    \"\"\"Creates a CNN model for feature extraction from grids\"\"\"\n","    model = models.Sequential([\n","        layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n","        layers.BatchNormalization(),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(128, (3, 3), activation='relu'),\n","        layers.BatchNormalization(),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(256, (3, 3), activation='relu'),\n","        layers.BatchNormalization(),\n","        layers.Flatten(),\n","        layers.Dense(256, activation='relu'),\n","        layers.BatchNormalization(),\n","        layers.Dropout(0.3),\n","        layers.Dense(256, name='feature_vector')\n","    ])\n","    return model\n","\n","# Re-instantiate the solver with the new feature extractor\n","solver = NeuralSymbolicSolver()\n","\n","# Prepare training examples\n","training_examples = []\n","for case_id, case_data in train_data.items():\n","    for example in case_data['train']:\n","        training_examples.append({\n","            'input': example['input'],\n","            'output': example['output']\n","        })\n","\n","# Train the solver again with the new feature extractor\n","solver.train(training_examples[:500], epochs=15, batch_size=16)\n","\n","# Test on a sample case\n","sample_case = list(train_data.values())[0]\n","input_grid = sample_case['train'][0]['input']\n","output_grid = sample_case['train'][0]['output']\n","\n","solution = solver.solve(input_grid, output_grid)\n","print(f\"Solution: {solution}\")\n","\n","# Visualize results\n","if solution:\n","    result = solver.execute_program(input_grid, solution)\n","    print(\"Original Input:\")\n","    print(np.array(input_grid))\n","    print(\"\\nSolved Output:\")\n","    print(result)\n","    print(\"\\nTarget Output:\")\n","    print(np.array(output_grid))"],"id":"037deb62","execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - loss: 2.2246\n","Epoch 2/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 1.8758\n","Epoch 3/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 1.6460\n","Epoch 4/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - loss: 1.4437\n","Epoch 5/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - loss: 1.3109\n","Epoch 6/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - loss: 1.1844\n","Epoch 7/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - loss: 0.9679\n","Epoch 8/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 155ms/step - loss: 0.7718\n","Epoch 9/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.6470\n","Epoch 10/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - loss: 0.5944\n","Epoch 11/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.4237\n","Epoch 12/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - loss: 0.5849\n","Epoch 13/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.3003\n","Epoch 14/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.2336\n","Epoch 15/15\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - loss: 0.3008\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d1fd3ae6f20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n","Solution: None\n"]}]},{"cell_type":"markdown","metadata":{"id":"f66e6afb"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","- The `find_best_primitive` function was enhanced to iterate through all available primitives and use negative mean squared error as a similarity metric to find the best one.\n","- The number of top programs to try was increased from 10 to 50 to broaden the search for a solution.\n","- The model was trained with more data (500 examples instead of 100) and for more epochs (15 instead of 5) to improve its learning. The training loss decreased from around 2.2 to approximately 0.27, indicating that the model was learning from the additional data.\n","- The feature extractor was refined by adding `BatchNormalization` layers, increasing the number of filters in the convolutional layers, and increasing the number of units in the final dense layer to capture more complex features.\n","- Despite all the enhancements made to the solver, including a more robust primitive selection, an expanded program search, improved training, and a refined feature extractor, the solver consistently failed to find a solution to the sample ARC task.\n","\n","### Insights or Next Steps\n","- The failure to find a solution suggests that the current set of primitives in the Domain-Specific Language (DSL) may be insufficient to solve the task. It's recommended to explore adding more complex or domain-specific primitives.\n","- The current program synthesis approach relies on a simple search over ranked programs. A more sophisticated search algorithm, such as a beam search or a genetic algorithm, could be more effective at exploring the program space and finding a solution.\n"],"id":"f66e6afb"}],"metadata":{"kernelspec":{"display_name":"kaggle","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}